{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (gensim, konlpy ë“± í¬í•¨)\n",
        "!pip install pandas konlpy gensim numpy\n",
        "\n",
        "# 2. Google Drive ë§ˆìš´íŠ¸\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JYMIc4CEfEhA",
        "outputId": "32d8534a-1ebb-48b4-8d12-c608d4728846"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Collecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading jpype1-1.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from konlpy) (6.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from JPype1>=0.7.0->konlpy) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jpype1-1.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (495 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m495.9/495.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: JPype1, konlpy, gensim\n",
            "Successfully installed JPype1-1.6.0 gensim-4.4.0 konlpy-0.6.0\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnVBvzmDDWcF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c633bdb-098a-4da1-8df0-5bd25b7a84c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ [Start] ì±… ë‹¨ìœ„ ë°ì´í„° í†µí•© ì§‘ê³„ (koELECTRA ê¸°ë°˜) ì‹œì‘...\n",
            "\n",
            "Target Folder: ë¦¬ë·°DB_KoELECTRA\n",
            "Output File: ë¦¬ë·°DB_KoELECTRA_Book_Summary_koELECTRA.csv\n",
            "íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\n",
            " koELECTRA ê¸°ë°˜ ë¶„ì„ ë° ì§‘ê³„ ì‘ì—…ì´ ëª¨ë‘ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "\n",
        "# =============================================================================\n",
        "# 1. 6ëŒ€ ì§€í‘œ ë§¤í•‘ ì‚¬ì „ (DNA ì§€í‘œ ê³„ì‚°)\n",
        "# =============================================================================\n",
        "\n",
        "INDICATOR_MAP = {\n",
        "    # [ê²°í•]\n",
        "    'count_fatigue': [\n",
        "        'ì§€ì¹˜ë‹¤', 'í”¼ê³¤í•˜ë‹¤', 'í˜ë“¤ë‹¤', 'ì–´ë µë‹¤', 'ë‚œí•´í•˜ë‹¤', 'ë³µì¡í•˜ë‹¤', 'ì§€ë£¨í•˜ë‹¤', 'ì¡¸ë¦¬ë‹¤', 'ì§€ì¹œ', 'ì§€ì³', 'í”¼ê³¤',\n",
        "        'ì½ê¸° í˜ë“ ', 'ì½ê¸° í˜ë“¤', 'ì´í•´í•˜ê¸° í˜ë“ ', 'ì´í•´ ë¶ˆê°€', 'ì§„ë„ê°€ ì•ˆ', 'ë¨¸ë¦¬ ì•„í”ˆ', 'ë¨¸ë¦¬ ì•„íŒŒ', 'ê¸°ë¹¨ë¦¼', 'ê¸°ë¹¨ë ¤',\n",
        "        'ìˆ˜ë©´ì œ', 'ì ì˜¨ë‹¤', 'ì§‘ì¤‘ ì•ˆ', 'í¬ê¸°', 'í•˜ì°¨', 'ë®ì—ˆ',\n",
        "        'ì†ì´ ì•ˆ', 'ëê¹Œì§€ ëª»', 'ì§€ê²¨ì›Œ', 'ë”°ë¶„', 'ì§€ì³ì„œ', 'ì¥ë²½', 'ë‘êº¼ìš´', 'ì‰½ì§€ ì•Š'\n",
        "    ],\n",
        "    'count_disappointment': [\n",
        "        'ì¬ë¯¸ì—†ë‹¤', 'ì‹¤ë§í•˜ë‹¤', 'ì•„ê¹ë‹¤', 'ë³„ë¡œë‹¤', 'ìµœì•…ì´ë‹¤', 'ë…¸ì¼', 'ì¬ë¯¸ì—†', 'ì‹¤ë§', 'ì‹¤ë§ìŠ¤', 'ê±°í’ˆ',\n",
        "        'ë‚šì˜€', 'ë‚šì„', 'ë°”ì´ëŸ´', 'ê´‘ê³ ', 'ëˆ ì•„ê¹', 'ëˆì•„ê¹', 'ëˆë‚­ë¹„', 'ì‹œê°„ ì•„ê¹', 'ì‹œê°„ë‚­ë¹„', 'ì‹œê°„ì•„ê¹',\n",
        "        'ë¹„ì¶”', 'ë³„ë¡œ', 'ë‚´ìš© ì—†', 'ë‚´ìš©ì—†', 'ë¹ˆì•½', 'ê²‰ë©‹', 'ì˜¤íƒ€', 'ë²ˆì—­', 'íŒŒì†','ì‹¤ë§ì„','ì˜ì•„','ì‹œì‹œí•˜','ë³„ê±° ì—†',\n",
        "        'ë¶ˆë§Œ', 'í—ˆìœ„', 'ê³¼ì¥', 'ê¸°ëŒ€ ì´í•˜', 'ê¸°ëŒ€ë§Œí¼', 'í—ˆì ‘', 'í€„ë¦¬í‹°', 'ì‹¤ë§ê°', 'ë¶ˆë§Œì¡±', 'í™˜ë¶ˆ', 'ê´œíˆ', 'í›„íšŒëœ'\n",
        "    ],\n",
        "    'count_skepticism': [\n",
        "        'ë»”í•˜ë‹¤', 'ì§„ë¶€í•˜ë‹¤', 'ë‹¹ì—°í•˜ë‹¤', 'ì¶”ìƒì ì´ë‹¤', 'ëœ¬êµ¬ë¦„', 'ë‹¹ì—°í•œ', 'ë»”í•œ', 'ì¶”ìƒì ', 'ë¹„í˜„ì‹¤ì ', 'ì™€ë‹¿ì§€',\n",
        "        'ê´´ë¦¬ê°', 'ì ìš©í•˜ê¸° í˜ë“ ', 'ì ìš© ë¶ˆê°€', 'ì´ìƒì ', 'ëˆ„êµ¬ë‚˜ ì•„ëŠ”', 'ë‹¤ ì•„ëŠ”', 'ë„ì›€ ì•ˆ', 'ê·¸ì € ê·¸ëŸ°', 'ì•Œë§¹ì´',\n",
        "        'ì§œê¹ê¸°', 'ì›ë¡ ì ', 'êµê³¼ì„œ','ì™€ë‹¿ì§€ ì•Š','ì‹ìƒí•œ','ì§„ë¶€í•˜ë‹¤','ì§„ë¶€í•œ',\n",
        "        'ì‹ìƒ', 'ë»”í•œ ì´ì•¼ê¸°', 'ìƒˆë¡œìš´ ë‚´ìš©ì´', 'í‰ì´í•œ', 'ëœ¬êµ¬ë¦„ ì¡', 'ë‚´ìš© ë¹ˆì•½', 'ì‹¤ì†ì´ ì—†', 'ê³µí—ˆ', 'ì‹¤ì²œí•˜ê¸° í˜ë“ ', 'ì¼ë°˜ì ì¸'\n",
        "    ],\n",
        "    # [ì¶©ì¡±]\n",
        "    'count_healing': [\n",
        "        'ìœ„ë¡œí•˜ë‹¤', 'ì¹˜ìœ í•˜ë‹¤', 'ê³µê°í•˜ë‹¤', 'í¸ì•ˆí•˜ë‹¤', 'ë”°ëœ»í•˜ë‹¤', 'í–‰ë³µí•˜ë‹¤', 'ìœ„ë¡œ', 'íë§', 'ë”°ëœ»í•œ', 'ë”°ìŠ¤í•œ',\n",
        "        'ê°ë™', 'ëˆˆë¬¼', 'ìš¸ì»¥', 'ì¹˜ìœ ', 'ê³µê°', 'ë¨¹ë¨¹', 'ë§ˆìŒ', 'í–‰ë³µ', 'ì„ ë¬¼', 'í¸ì•ˆ', 'ë‹¤ë…', 'ì•ˆì‹', 'íœ´ì‹',\n",
        "        'ë²…ì°¨', 'ìœ„ì•ˆ', 'ê°€ìŠ´', 'ë²…ì°¬', 'ë”°ëœ»í•¨', 'ë­‰í´', 'íë§ë˜ëŠ”', 'ë§ˆìŒì´', 'ë“ ë“ ', 'ìœ„ë¡œë°›', 'í˜ì´', 'ëˆˆë¬¼ í‘í‘'\n",
        "    ],\n",
        "    'count_insight': [\n",
        "        'ìœ ìµí•˜ë‹¤', 'ëª…í™•í•˜ë‹¤', 'ì‹ ì„ í•˜ë‹¤', 'ê¹Šë‹¤', 'í†µì°°í•˜ë‹¤', 'íƒì›”í•˜ë‹¤', 'ìœ ìµ', 'ëª…í™•', 'ì‹ ì„ ', 'ê¹Šì´', 'í†µì°°',\n",
        "        'ì§€ì‹', 'ë°°ì›€', 'ì•Œì°¬', 'íƒì›”', 'ë…¼ë¦¬ì ', 'ì„¤ë“ë ¥', 'ê¹”ë”', 'ì™„ë²½', 'ë„ì›€', 'ì„±ì¥', 'ë™ê¸°ë¶€ì—¬', 'ìƒˆë¡œìš´ ì‹œê°', 'ê´€ì ',\n",
        "        'ì‹¤ìš©ì ', 'ì‹¤ìš©ì„±', 'ê°€ì´ë“œ', 'ì¸ìƒì˜', 'ê¹¨ë‹«', 'ê°€ë¥´ì¹¨', 'ë°©í–¥', 'ì •ë¦¬ëœ', 'ê¹”ë”í•˜ê²Œ', 'ìƒˆë¡­ê²Œ', 'ì‚¬ê³ ', 'ìƒê°ì˜'\n",
        "    ],\n",
        "    'count_fun': [\n",
        "        'ì¬ë¯¸ìˆë‹¤', 'í¥ë¯¸ë¡­ë‹¤', 'ëª°ì…í•˜ë‹¤', 'ë¹ ì ¸ë“¤ë‹¤', 'ì¬ë°Œ', 'ì¬ë¯¸ìˆ', 'í¥ë¯¸', 'ëª°ì…', 'ìˆ ìˆ ', 'ì½íˆë‹¤', 'ì½íŒë‹¤',\n",
        "        'ìˆœì‚­', 'ì‹œê°„ê°€ëŠ”ì¤„', 'ë°¤ìƒˆ', 'ê°€ë…ì„±', 'í¡ì…ë ¥', 'ì¸ìƒì±…', 'ê°•ì¶”', 'ì¶”ì²œ', 'ì†Œì¥', 'í•„ë…',\n",
        "        'ì™„ë…', 'ì•‰ì€ ìë¦¬ì—ì„œ', 'ë‹¨ìˆ¨ì—', 'í¥ë¯¸ì§„ì§„', 'ì†ì—ì„œ ë†“ì„ ìˆ˜', 'ìµœì• ', 'ë‹¤ìŒí¸', 'ê¸°ë‹¤ë ¤', 'í˜ì´ì§€ê°€', 'í˜¸ê¸°ì‹¬', 'ê¸´ì¥ê°'\n",
        "    ]\n",
        "}\n",
        "\n",
        "SAFE_PATTERNS = [\n",
        "    'ë§Œë‚˜ê¸° í˜ë“¤', 'ì°¾ê¸° í˜ë“¤', 'ë³´ê¸° í˜ë“¤', 'êµ¬í•˜ê¸° í˜ë“¤',\n",
        "    'í˜ë“¤ ë•Œ', 'í˜ë“¤ ìˆ˜', 'í˜ë“¤ ì •ë„ë¡œ', 'ì•Šì•„ í˜ë“¤',\n",
        "    'ì½ê¸° í˜ë“¤ì§€ ì•Š', 'ì´í•´í•˜ê¸° í˜ë“¤ì§€ ì•Š', 'ì§€ë£¨í•˜ì§€ ì•Š', 'ì¬ë¯¸ì—†ì§€ ì•Š'\n",
        "]\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# í—¬í¼ í•¨ìˆ˜: ì»¬ëŸ¼ ì´ë¦„ ìœ ì—°í•˜ê²Œ ì°¾ê¸°\n",
        "# =============================================================================\n",
        "def sanitize_column_name(name):\n",
        "    \"\"\"ì»¬ëŸ¼ ì´ë¦„ì˜ ëŒ€ì†Œë¬¸ì, ê³µë°±, ì–¸ë”ë°”, ì ì„ ì œê±°í•˜ê³  ì†Œë¬¸ìë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
        "    if isinstance(name, str):\n",
        "        return re.sub(r'[\\s_\\.]', '', name).lower()\n",
        "    return name\n",
        "\n",
        "def get_col(df, target_name):\n",
        "    \"\"\"ì •ê·œí™”ëœ ì´ë¦„ìœ¼ë¡œ ì»¬ëŸ¼ì„ ì°¾ì•„ì„œ ì›ë˜ ì´ë¦„ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
        "    target_sanitized = sanitize_column_name(target_name)\n",
        "    sanitized_cols = {sanitize_column_name(col): col for col in df.columns}\n",
        "\n",
        "    if target_sanitized in sanitized_cols:\n",
        "        return sanitized_cols[target_sanitized]\n",
        "    return None\n",
        "\n",
        "# =============================================================================\n",
        "# 2. ë¶„ì„ í•¨ìˆ˜ (ë¦¬ë·° ë‹¨ìœ„ ê³„ì‚°)\n",
        "# =============================================================================\n",
        "\n",
        "def count_indicators(row):\n",
        "    \"\"\"ë¦¬ë·° í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ 6ëŒ€ ê°ì • DNA í‚¤ì›Œë“œ ë¹ˆë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\"\"\"\n",
        "    text_source = str(row.get('review_text', ''))\n",
        "    is_safe = any(safe in text_source for safe in SAFE_PATTERNS)\n",
        "\n",
        "    counts = {}\n",
        "    for col_name, keywords in INDICATOR_MAP.items():\n",
        "        count = 0\n",
        "        is_negative_indicator = col_name in ['count_fatigue', 'count_disappointment', 'count_skepticism']\n",
        "\n",
        "        # ì•ˆì „ íŒ¨í„´ì´ ë°œê²¬ë˜ë©´ ë¶€ì • ì§€í‘œ ì¹´ìš´íŠ¸ë¥¼ 0ìœ¼ë¡œ ì²˜ë¦¬ (ì˜¤ë¶„ë¥˜ ë°©ì§€)\n",
        "        if is_negative_indicator and is_safe:\n",
        "            count = 0\n",
        "        else:\n",
        "            for kw in keywords:\n",
        "                count += text_source.count(kw)\n",
        "        counts[col_name] = count\n",
        "    return pd.Series(counts)\n",
        "\n",
        "# =============================================================================\n",
        "# 3. í´ë” ì²˜ë¦¬ ë° ì±… ë‹¨ìœ„ ìš”ì•½ (Book Aggregator)\n",
        "# =============================================================================\n",
        "\n",
        "# ë¦¬ë·° ë°ì´í„°ê°€ ì €ì¥ëœ Google Drive ê²½ë¡œ\n",
        "input_folders = [\n",
        "    '/content/drive/MyDrive/project/ë¦¬ë·°DB_KoELECTRA/'\n",
        "]\n",
        "\n",
        "def read_csv_with_encoding(file_path):\n",
        "    \"\"\"ì¸ì½”ë”© ì˜¤ë¥˜ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ utf-8, cp949 ìˆœìœ¼ë¡œ ì‹œë„í•˜ëŠ” í—¬í¼ í•¨ìˆ˜\"\"\"\n",
        "    try:\n",
        "        return pd.read_csv(file_path, encoding='utf-8')\n",
        "    except UnicodeDecodeError:\n",
        "        try:\n",
        "            return pd.read_csv(file_path, encoding='cp949')\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Failed to read CSV with both utf-8 and cp949: {e}\")\n",
        "\n",
        "def aggregate_books(folder_list):\n",
        "    print(\"ğŸš€ [Start] ì±… ë‹¨ìœ„ ë°ì´í„° í†µí•© ì§‘ê³„ (koELECTRA ê¸°ë°˜) ì‹œì‘...\\n\")\n",
        "\n",
        "    POSITIVE_THRESHOLD = 0.5\n",
        "    NEGATIVE_THRESHOLD = -0.5\n",
        "    MAX_RATING_FOR_NORMALIZATION = 5.0\n",
        "\n",
        "    for input_path in folder_list:\n",
        "        folder_name = os.path.basename(input_path.rstrip(os.sep))\n",
        "        clean_name = folder_name.replace('(token)', '')\n",
        "\n",
        "        output_filename = f\"{clean_name}_Book_Summary_koELECTRA.csv\"\n",
        "        output_path = os.path.join(os.path.dirname(input_path), output_filename)\n",
        "\n",
        "        print(f\"Target Folder: {folder_name}\")\n",
        "        print(f\"Output File: {output_filename}\")\n",
        "\n",
        "        files = glob.glob(os.path.join(input_path, '*.csv'))\n",
        "        if not files:\n",
        "            print(\"íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "            continue\n",
        "\n",
        "        book_summary_list = []\n",
        "\n",
        "        for file_path in tqdm(files, desc=\" Â  â””â”€ Aggregating\"):\n",
        "            file_base_name = os.path.basename(file_path)\n",
        "            try:\n",
        "                df = read_csv_with_encoding(file_path)\n",
        "\n",
        "                # ì»¬ëŸ¼ ì´ë¦„ì˜ ì•ë’¤ ê³µë°± ì œê±°\n",
        "                df.columns = df.columns.str.strip()\n",
        "\n",
        "                # í•„ìˆ˜ KoELECTRA ì»¬ëŸ¼ ìœ ì—°í•˜ê²Œ ì°¾ê¸°\n",
        "                sentiment_col_name = get_col(df, 'sent_score_pm1')\n",
        "                rating_col_name = get_col(df, 'rating_5pt')\n",
        "                review_text_col_name = get_col(df, 'review_text')\n",
        "\n",
        "                #  íŒŒì¼ì´ ìŠ¤í‚µë  ë•Œ ì»¬ëŸ¼ ì •ë³´ë¥¼ ì¶œë ¥\n",
        "                missing_cols_list = []\n",
        "                if not sentiment_col_name: missing_cols_list.append('sent_score_pm1')\n",
        "                if not rating_col_name: missing_cols_list.append('rating_5pt')\n",
        "                if not review_text_col_name: missing_cols_list.append('review_text')\n",
        "\n",
        "                if missing_cols_list:\n",
        "                    print(f\"\\n Â   SKIPPED: {file_base_name}\")\n",
        "                    print(f\" Â  Â  â””â”€ ëˆ„ë½ ì»¬ëŸ¼: {', '.join(missing_cols_list)}\")\n",
        "                    print(f\" Â  Â  â””â”€ íŒŒì¼ ì»¬ëŸ¼ ëª©ë¡: {list(df.columns)}\") # ì‹¤ì œ íŒŒì¼ ì»¬ëŸ¼ëª…ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
        "                    continue\n",
        "                # ì§„ë‹¨ìš© ì¶œë ¥ ì¶”ê°€ ë\n",
        "\n",
        "                # 1. KoELECTRA ì ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ sentiment_score ì •ì˜ (ê¸/ë¶€ì • ì§€í‘œ ëŒ€ì²´)\n",
        "                df['sentiment_score'] = df[sentiment_col_name].astype(float)\n",
        "\n",
        "                # 2. í‰ì  ì»¬ëŸ¼ ì •ì˜\n",
        "                df['rating_val'] = df[rating_col_name].astype(float).fillna(0)\n",
        "\n",
        "                # ê±°í’ˆ ì§€ìˆ˜ ê³„ì‚°\n",
        "                df['bubble_index'] = (df['rating_val'] / MAX_RATING_FOR_NORMALIZATION) - df['sentiment_score']\n",
        "\n",
        "\n",
        "                # 3. DNA ì§€í‘œ ê³„ì‚°ì„ ìœ„í•´ review_text ì»¬ëŸ¼ ì •ì˜\n",
        "                df['review_text'] = df[review_text_col_name].fillna('')\n",
        "\n",
        "                freq_df = df.apply(count_indicators, axis=1)\n",
        "                df = pd.concat([df, freq_df], axis=1)\n",
        "\n",
        "                # 4. ê¸ì •/ë¶€ì • ë¦¬ë·° ë¹„ìœ¨ ê³„ì‚° (KoELECTRA ì ìˆ˜ ê¸°ë°˜)\n",
        "                total_reviews = len(df)\n",
        "                if total_reviews == 0: continue\n",
        "\n",
        "                pos_reviews = (df['sentiment_score'] >= POSITIVE_THRESHOLD).sum()\n",
        "                neg_reviews = (df['sentiment_score'] <= NEGATIVE_THRESHOLD).sum()\n",
        "\n",
        "                pos_ratio = round(pos_reviews / total_reviews, 3) if total_reviews > 0 else 0\n",
        "                neg_ratio = round(neg_reviews / total_reviews, 3) if total_reviews > 0 else 0\n",
        "\n",
        "                # 5. ì±… ì •ë³´ ìš”ì•½ - ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (ìœ ì—°í•˜ê²Œ ì»¬ëŸ¼ ì°¾ê¸°)\n",
        "                title_col = get_col(df, 'title')\n",
        "                author_col = get_col(df, 'author')\n",
        "                category_col = get_col(df, 'category')\n",
        "                publisher_col = get_col(df, 'publisher')\n",
        "\n",
        "                book_meta = {\n",
        "                    'Title': df[title_col].iloc[0] if title_col and not df[title_col].empty else file_base_name.replace('.csv', ''),\n",
        "                    'Author': df[author_col].iloc[0] if author_col and not df[author_col].empty else 'Unknown',\n",
        "                    'Category': df[category_col].iloc[0] if category_col and not df[category_col].empty else 'Unknown',\n",
        "                    'Publisher': df[publisher_col].iloc[0] if publisher_col and not df[publisher_col].empty else 'Unknown',\n",
        "                    'Review_Count': total_reviews\n",
        "                }\n",
        "\n",
        "                stats = {\n",
        "                    'Sum_Fatigue': df['count_fatigue'].sum(),\n",
        "                    'Sum_Disappointment': df['count_disappointment'].sum(),\n",
        "                    'Sum_Skepticism': df['count_skepticism'].sum(),\n",
        "                    'Sum_Healing': df['count_healing'].sum(),\n",
        "                    'Sum_Insight': df['count_insight'].sum(),\n",
        "                    'Sum_Fun': df['count_fun'].sum(),\n",
        "\n",
        "                    'Avg_Rating': round(df['rating_val'].mean(), 2),\n",
        "                    'Avg_Sentiment': round(df['sentiment_score'].mean(), 3),\n",
        "                    'Avg_Bubble_Index': round(df['bubble_index'].mean(), 3),\n",
        "\n",
        "                    'pos_review_ratio': pos_ratio,\n",
        "                    'neg_review_ratio': neg_ratio\n",
        "                }\n",
        "\n",
        "                book_summary_list.append({**book_meta, **stats})\n",
        "\n",
        "            except Exception as e:\n",
        "                # ì¼ë°˜ì ì¸ ì²˜ë¦¬ ì˜¤ë¥˜ ì¶œë ¥\n",
        "                print(f\"\\n Â   Error processing {file_base_name}: {e}\")\n",
        "                pass\n",
        "\n",
        "        # 6. ì €ì¥ ë° í•œê¸€ ì»¬ëŸ¼ ë³€í™˜\n",
        "        if book_summary_list:\n",
        "            summary_df = pd.DataFrame(book_summary_list)\n",
        "\n",
        "            # í•œê¸€ ì»¬ëŸ¼ëª… ë§¤í•‘\n",
        "            rename_map = {\n",
        "                'Title': 'ë„ì„œëª…', 'Author': 'ì €ì', 'Category': 'ë¶„ì•¼', 'Publisher': 'ì¶œíŒì‚¬', 'Review_Count': 'ì´_ë¦¬ë·°_ìˆ˜',\n",
        "                'Sum_Fatigue': 'ì‹¬ë¦¬ì _í”¼ë¡œ_ë¹ˆë„', 'Sum_Disappointment': 'ì½˜í…ì¸ _ì‹¤ë§_ë¹ˆë„', 'Sum_Skepticism': 'ì‹¤íš¨ì„±_ë¶€ì¡±_ë¹ˆë„',\n",
        "                'Sum_Healing': 'ì •ì„œì _ìœ„ë¡œ_ë¹ˆë„', 'Sum_Insight': 'ì§€ì _í†µì°°_ë¹ˆë„', 'Sum_Fun': 'ëª°ì…ê°_ì¬ë¯¸_ë¹ˆë„',\n",
        "                'Avg_Rating': 'í‰ê· _í‰ì ', 'Avg_Sentiment': 'í‰ê· _ê°ì„±_ì ìˆ˜', 'Avg_Bubble_Index': 'í‰ê· _ê±°í’ˆ_ì§€ìˆ˜',\n",
        "                'pos_review_ratio': 'ê°•í•œ_ê¸ì •_ë¦¬ë·°_ë¹„ìœ¨',\n",
        "                'neg_review_ratio': 'ê°•í•œ_ë¶€ì •_ë¦¬ë·°_ë¹„ìœ¨'\n",
        "            }\n",
        "            summary_df = summary_df.rename(columns=rename_map)\n",
        "\n",
        "            # ìµœì¢… ì»¬ëŸ¼ ìˆœì„œ ì§€ì •\n",
        "            final_cols = [\n",
        "                'ë„ì„œëª…', 'ì €ì', 'ë¶„ì•¼', 'ì¶œíŒì‚¬', 'ì´_ë¦¬ë·°_ìˆ˜',\n",
        "                'ì‹¬ë¦¬ì _í”¼ë¡œ_ë¹ˆë„', 'ì½˜í…ì¸ _ì‹¤ë§_ë¹ˆë„', 'ì‹¤íš¨ì„±_ë¶€ì¡±_ë¹ˆë„',\n",
        "                'ì •ì„œì _ìœ„ë¡œ_ë¹ˆë„', 'ì§€ì _í†µì°°_ë¹ˆë„', 'ëª°ì…ê°_ì¬ë¯¸_ë¹ˆë„',\n",
        "                'í‰ê· _í‰ì ', 'í‰ê· _ê°ì„±_ì ìˆ˜', 'í‰ê· _ê±°í’ˆ_ì§€ìˆ˜',\n",
        "                'ê°•í•œ_ê¸ì •_ë¦¬ë·°_ë¹„ìœ¨', 'ê°•í•œ_ë¶€ì •_ë¦¬ë·°_ë¹„ìœ¨'\n",
        "            ]\n",
        "            summary_df = summary_df[[c for c in final_cols if c in summary_df.columns]]\n",
        "\n",
        "            summary_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
        "            print(f\" Â ì €ì¥ ì™„ë£Œ: {output_path}\\n\")\n",
        "        else:\n",
        "            print(\" Â ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\\n\")\n",
        "\n",
        "    print(\" koELECTRA ê¸°ë°˜ ë¶„ì„ ë° ì§‘ê³„ ì‘ì—…ì´ ëª¨ë‘ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    aggregate_books(input_folders)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 0. í™˜ê²½ ì„¤ì •\n",
        "# -----------------------------------------------------------\n",
        "plt.rcParams['font.family'] = 'NanumGothic'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 1. ì‚¬ìš©ì ì •ì˜ ë³€ìˆ˜ ë° íŒŒì¼ ì„¤ì •\n",
        "# -----------------------------------------------------------\n",
        "# ìƒì„±ëœ í†µí•© ìš”ì•½ íŒŒì¼ ê²½ë¡œë¥¼ ì •í™•íˆ ì§€ì •\n",
        "SUMMARY_FILE_PATH = \"/content/drive/MyDrive/project/ë¦¬ë·°DB_KoELECTRA_Book_Summary_koELECTRA.csv\"\n",
        "MIN_REVIEW_COUNT = 10  # ë¶„ì„ì— í¬í•¨ì‹œí‚¬ ìµœì†Œ ë¦¬ë·° ìˆ˜\n",
        "\n",
        "# ìµœì¢… CSV íŒŒì¼ì˜ í•œêµ­ì–´ ì»¬ëŸ¼ì„ ë¶„ì„ì— ì‚¬ìš©í•  ì˜ì–´/ë‹¨ì¶•ëª…ìœ¼ë¡œ ë§¤í•‘\n",
        "CORE_COLS_MAP = {\n",
        "    'ë„ì„œëª…': 'title',\n",
        "    'ì €ì': 'author',\n",
        "    'ë¶„ì•¼': 'category',\n",
        "    'ì´_ë¦¬ë·°_ìˆ˜': 'total_reviews',\n",
        "    'í‰ê· _ê±°í’ˆ_ì§€ìˆ˜': 'bubble_index',\n",
        "    'í‰ê· _í‰ì ': 'avg_rating',\n",
        "    'í‰ê· _ê°ì„±_ì ìˆ˜': 'avg_sentiment',\n",
        "    'ì½˜í…ì¸ _ì‹¤ë§_ë¹ˆë„': 'disappoint_freq',\n",
        "    'ì‹¤íš¨ì„±_ë¶€ì¡±_ë¹ˆë„': 'skepticism_freq',\n",
        "}\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 2. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "print(f\"í†µí•© ìš”ì•½ íŒŒì¼ ë¡œë“œ ì‹œì‘: {os.path.basename(SUMMARY_FILE_PATH)}\")\n",
        "\n",
        "def read_summary_file(filename):\n",
        "    \"\"\"ì¸ì½”ë”© ì˜¤ë¥˜ë¥¼ ì²˜ë¦¬í•˜ë©° CSV íŒŒì¼ì„ ì½ì–´ì˜¤ëŠ” í—¬í¼ í•¨ìˆ˜\"\"\"\n",
        "    try:\n",
        "        # ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” UTF-8 BOM ì¸ì½”ë”©ìœ¼ë¡œ ì‹œë„\n",
        "        return pd.read_csv(filename, encoding='utf-8-sig')\n",
        "    except:\n",
        "        # ë‹¤ë¥¸ ì¸ì½”ë”©ìœ¼ë¡œ ì¬ì‹œë„\n",
        "        return pd.read_csv(filename, encoding='cp949')\n",
        "\n",
        "df = read_summary_file(SUMMARY_FILE_PATH)\n",
        "\n",
        "if df is None or df.empty:\n",
        "    raise FileNotFoundError(\"íŒŒì¼ì„ ë¡œë“œí•˜ì§€ ëª»í–ˆê±°ë‚˜ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ê²½ë¡œì™€ íŒŒì¼ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
        "\n",
        "# ì»¬ëŸ¼ëª… ì •ë¦¬ ë° í‘œì¤€í™”\n",
        "df.columns = df.columns.str.strip()\n",
        "df_total_summary = df.rename(columns=CORE_COLS_MAP, errors='ignore')\n",
        "\n",
        "# í•„ìˆ˜ ì»¬ëŸ¼ ê²€ì¦\n",
        "required_cols = list(CORE_COLS_MAP.values())\n",
        "if not all(col in df_total_summary.columns for col in required_cols):\n",
        "    missing_cols = [col for col in required_cols if col not in df_total_summary.columns]\n",
        "    print(f\"í•„ìˆ˜ ë¶„ì„ ì»¬ëŸ¼ ëˆ„ë½: {missing_cols}\")\n",
        "    # ëˆ„ë½ëœ ì»¬ëŸ¼ì€ 0ìœ¼ë¡œ ì±„ìš°ê±°ë‚˜, ë¶„ì„ì—ì„œ ì œì™¸ë˜ëŠ” ì»¬ëŸ¼ë§Œ ë¬´ì‹œ\n",
        "    for col in ['disappoint_freq', 'skepticism_freq']:\n",
        "        if col not in df_total_summary.columns:\n",
        "            df_total_summary[col] = 0\n",
        "\n",
        "print(f\"ìµœì¢… í†µí•©ëœ ë¶„ì„ ë°ì´í„°í”„ë ˆì„ í¬ê¸°: {len(df_total_summary)} í–‰\")\n",
        "\n",
        "# ë¶„ì„ìš© ë°ì´í„° í•„í„°ë§ (ìµœì†Œ ë¦¬ë·° ìˆ˜ ì¶©ì¡±)\n",
        "df_filtered_analysis = df_total_summary[\n",
        "    df_total_summary['total_reviews'] >= MIN_REVIEW_COUNT\n",
        "].copy()\n",
        "print(f\"ìµœì†Œ ë¦¬ë·° ìˆ˜({MIN_REVIEW_COUNT}ê°œ) í•„í„°ë§ í›„: {len(df_filtered_analysis)} í–‰\")\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 3. ê±°í’ˆ ë„ì„œ Top 10 ì„ ì • (bubble_top10_overall ë³€ìˆ˜ ì •ì˜)\n",
        "# -----------------------------------------------------------\n",
        "bubble_top10_overall = df_filtered_analysis.sort_values(\n",
        "    by='bubble_index',\n",
        "    ascending=False,\n",
        "    na_position='last'\n",
        ").head(10)\n",
        "\n",
        "print(\"\\n=======================================================\")\n",
        "print(\"í†µí•© ë² ìŠ¤íŠ¸ì…€ëŸ¬ ê±°í’ˆ ë„ì„œ Top 10\")\n",
        "print(\"=======================================================\")\n",
        "\n",
        "# í‰ì -ê°ì„± ì ìˆ˜ ì°¨ì´ ê³„ì‚°\n",
        "bubble_top10_overall['rating_sentiment_gap'] = (\n",
        "    bubble_top10_overall['avg_rating'] - bubble_top10_overall['avg_sentiment']\n",
        ")\n",
        "\n",
        "final_result_top10 = bubble_top10_overall[[\n",
        "    'title',\n",
        "    'category', # ì¹´í…Œê³ ë¦¬ ì¶”ê°€\n",
        "    'bubble_index',\n",
        "    'avg_rating',\n",
        "    'avg_sentiment',\n",
        "    'rating_sentiment_gap',\n",
        "    'total_reviews',\n",
        "    'disappoint_freq',\n",
        "    'skepticism_freq' # ì‹¤íš¨ì„± ë¶€ì¡± ë¹ˆë„ ì¶”ê°€\n",
        "]].copy()\n",
        "\n",
        "print(final_result_top10.to_markdown(index=False, floatfmt=\".3f\"))\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 4. ì‹œê°í™” 1: ê±°í’ˆ êµ¬ê°„ Scatter Plot\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "\n",
        "# ë¦¬ë·° ìˆ˜ì— ë”°ë¼ ì  í¬ê¸° ì„¤ì •\n",
        "df_filtered_analysis['plot_size'] = df_filtered_analysis['total_reviews'] / 50\n",
        "df_filtered_analysis['plot_size'] = df_filtered_analysis['plot_size'].clip(lower=10, upper=300)\n",
        "\n",
        "plt.scatter(\n",
        "    df_filtered_analysis['bubble_index'],\n",
        "    df_filtered_analysis['avg_sentiment'],\n",
        "    alpha=0.4,\n",
        "    s=df_filtered_analysis['plot_size'],\n",
        "    color='gray',\n",
        "    label=f'ì „ì²´ ë„ì„œ (ë¦¬ë·° {MIN_REVIEW_COUNT}ê°œ ì´ìƒ)'\n",
        ")\n",
        "\n",
        "# Top 10 ë„ì„œ ì‹œê°í™”ìš© í¬ê¸° ì¡°ì •\n",
        "bubble_top10_overall['plot_size_top'] = bubble_top10_overall['total_reviews'] / 30\n",
        "bubble_top10_overall['plot_size_top'] = bubble_top10_overall['plot_size_top'].clip(lower=50, upper=400)\n",
        "\n",
        "plt.scatter(\n",
        "    bubble_top10_overall['bubble_index'],\n",
        "    bubble_top10_overall['avg_sentiment'],\n",
        "    alpha=1.0,\n",
        "    s=bubble_top10_overall['plot_size_top'],\n",
        "    color='red',\n",
        "    label='ê±°í’ˆ ë„ì„œ Top 10'\n",
        ")\n",
        "\n",
        "plt.title('í†µí•© ë² ìŠ¤íŠ¸ì…€ëŸ¬ ê±°í’ˆ ì§€ìˆ˜ vs. ë…ì ë§Œì¡±ë„', fontsize=18, pad=20)\n",
        "plt.xlabel('ê±°í’ˆ ì§€ìˆ˜ (Bubble Index)', fontsize=14)\n",
        "plt.ylabel('í‰ê·  ê°ì„± ì ìˆ˜ (ë…ì ë§Œì¡±ë„)', fontsize=14)\n",
        "plt.axvline(x=df_filtered_analysis['bubble_index'].mean(), color='blue', linestyle=':', label='í‰ê·  ê±°í’ˆ ì§€ìˆ˜')\n",
        "plt.axhline(y=df_filtered_analysis['avg_sentiment'].mean(), color='green', linestyle=':', label='í‰ê·  ê°ì„± ì ìˆ˜')\n",
        "plt.legend(fontsize=11)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 5. ì‹œê°í™” 2: ì¹´í…Œê³ ë¦¬ë³„ ê±°í’ˆ ì§€ìˆ˜ ì§‘ì¤‘ë„ ë¶„ì„\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "category_bubble = df_filtered_analysis.groupby('category')['bubble_index'].mean().reset_index()\n",
        "category_bubble = category_bubble.sort_values(by='bubble_index', ascending=False)\n",
        "top_n_category = 10\n",
        "category_bubble_top = category_bubble.head(top_n_category)\n",
        "\n",
        "plt.figure(figsize=(12, 7))\n",
        "sns.barplot(x='bubble_index', y='category', data=category_bubble_top, palette='viridis')\n",
        "plt.title(f' ìƒìœ„ {top_n_category}ê°œ ì¹´í…Œê³ ë¦¬ë³„ í‰ê·  ê±°í’ˆ ì§€ìˆ˜', fontsize=16)\n",
        "plt.xlabel('í‰ê·  ê±°í’ˆ ì§€ìˆ˜', fontsize=12)\n",
        "plt.ylabel('ì¹´í…Œê³ ë¦¬', fontsize=12)\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n=======================================================\")\n",
        "print(\"ì¢…í•© ë¶„ì„ ìš”ì•½ ê²°ê³¼ - Top 10 ì¹´í…Œê³ ë¦¬\")\n",
        "print(\"=======================================================\")\n",
        "print(category_bubble_top.to_markdown(index=False, floatfmt=\".3f\"))\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 6. ì‹¬í™” ë¶„ì„ 1: Top 10 ê±°í’ˆ ë„ì„œ ì¹´í…Œê³ ë¦¬ ë¶„í¬ (íŒŒì´ ì°¨íŠ¸)\n",
        "# -----------------------------------------------------------\n",
        "print(\"\\n=======================================================\")\n",
        "print(\"Top 10 ê±°í’ˆ ë„ì„œ ì¹´í…Œê³ ë¦¬ ë¶„í¬ ë¶„ì„\")\n",
        "print(\"=======================================================\")\n",
        "\n",
        "top10_category_counts = bubble_top10_overall['category'].value_counts().reset_index()\n",
        "top10_category_counts.columns = ['Category', 'Count']\n",
        "print(top10_category_counts.to_markdown(index=False))\n",
        "\n",
        "plt.figure(figsize=(9, 9))\n",
        "plt.pie(\n",
        "    top10_category_counts['Count'],\n",
        "    labels=top10_category_counts['Category'],\n",
        "    autopct='%1.1f%%',\n",
        "    startangle=140,\n",
        "    textprops={'fontsize': 12},\n",
        "    wedgeprops={'edgecolor': 'black', 'linewidth': 1}\n",
        ")\n",
        "plt.title('Top 10 ê±°í’ˆ ë„ì„œì˜ ì¹´í…Œê³ ë¦¬ë³„ ì ìœ ìœ¨', fontsize=18, pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 7. ì‹¬í™” ë¶„ì„ 2: ë¦¬ë·° ìˆ˜ê°€ ë§ì€ ë„ì„œ ê·¸ë£¹ì˜ ê±°í’ˆ ì§€ìˆ˜ í†µê³„ ë¹„êµ\n",
        "# -----------------------------------------------------------\n",
        "print(\"\\n=======================================================\")\n",
        "print(\"ë¦¬ë·° ìˆ˜ ê·¸ë£¹ë³„ ê±°í’ˆ ì§€ìˆ˜ í†µê³„ ë¹„êµ\")\n",
        "print(\"=======================================================\")\n",
        "\n",
        "# ë¦¬ë·° ìˆ˜ ê·¸ë£¹í™” (Quantile ê¸°ì¤€)\n",
        "df_filtered_analysis['review_quantile'] = pd.qcut(\n",
        "    df_filtered_analysis['total_reviews'],\n",
        "    q=[0, 0.5, 0.75, 1], # 50%, 50~75%, 75% ì´ìƒ ê·¸ë£¹ìœ¼ë¡œ ë¶„í• \n",
        "    labels=['í•˜ìœ„ 50%', 'ì¤‘ìœ„ 25%', 'ìƒìœ„ 25%'],\n",
        "    duplicates='drop'\n",
        ")\n",
        "\n",
        "bubble_by_review_group = df_filtered_analysis.groupby('review_quantile', observed=False)['bubble_index'].agg(['mean', 'median', 'count']).reset_index()\n",
        "bubble_by_review_group.columns = ['ë¦¬ë·°_ìˆ˜_ê·¸ë£¹', 'í‰ê· _ê±°í’ˆ_ì§€ìˆ˜', 'ì¤‘ì•™ê°’_ê±°í’ˆ_ì§€ìˆ˜', 'ë„ì„œ_ìˆ˜']\n",
        "\n",
        "print(bubble_by_review_group.to_markdown(index=False, floatfmt=\".3f\"))"
      ],
      "metadata": {
        "id": "ThvlqdTsDZjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 1. ìƒê´€ê³„ìˆ˜ ê³„ì‚° ë° í•´ì„\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "if 'df_total_summary' in locals() and not df_total_summary.empty:\n",
        "\n",
        "    # 1. ê³„ì‚°ì— ì‚¬ìš©í•  ì»¬ëŸ¼ì„ ì¶”ì¶œí•˜ê³  NaN ê°’ ì œê±°\n",
        "    correlation_df = df_total_summary[['popularity_index', 'avg_sentiment']].dropna()\n",
        "\n",
        "    if correlation_df.empty:\n",
        "        print(\"ê²½ê³ : ìƒê´€ê³„ìˆ˜ ê³„ì‚°ì— ì‚¬ìš©í•  ìœ íš¨í•œ ë°ì´í„°(popularity_index, avg_sentiment)ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "    else:\n",
        "        # 2. í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ ê³„ì‚° (rho)\n",
        "        correlation_coefficient = correlation_df['popularity_index'].corr(\n",
        "            correlation_df['avg_sentiment']\n",
        "        )\n",
        "\n",
        "        # 3. ê²°ê³¼ í•´ì„\n",
        "        if abs(correlation_coefficient) < 0.2:\n",
        "            interpretation = \"ë§¤ìš° ì•½í•œ ìƒê´€ê´€ê³„ ë˜ëŠ” ê±°ì˜ ë¬´ê´€í•¨\"\n",
        "        elif 0.2 <= abs(correlation_coefficient) < 0.4:\n",
        "            interpretation = \"ì•½í•œ ìƒê´€ê´€ê³„\"\n",
        "        else:\n",
        "            interpretation = \"ë³´í†µ ì´ìƒì˜ ìƒê´€ê´€ê³„\"\n",
        "\n",
        "        print(\"================================================================\")\n",
        "        print(\" ë² ìŠ¤íŠ¸ì…€ëŸ¬ ìˆœìœ„(ì¸ê¸° ì§€ìˆ˜) vs. ë…ì ë§Œì¡±ë„(ê°ì„± ì ìˆ˜) ìƒê´€ ë¶„ì„\")\n",
        "        print(\"================================================================\")\n",
        "        print(f\"ì „ì²´ ë„ì„œ ìˆ˜ (ê³„ì‚°ì— ì‚¬ìš©): {len(correlation_df)}ê°œ\")\n",
        "        print(f\"í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ (Ï): {correlation_coefficient:.4f}\")\n",
        "        print(f\"í•´ì„: {interpretation}\")\n",
        "        print(\" ìƒê´€ê³„ìˆ˜ê°€ 0ì— ê°€ê¹ë‹¤ëŠ” ê²ƒì€, ì±…ì˜ ìˆœìœ„ì™€ ë…ìì˜ ê°ì„± ë§Œì¡±ë„ëŠ” ê±°ì˜ ë¬´ê´€í•˜ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\")"
      ],
      "metadata": {
        "id": "gbvop2QWEtwA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}